{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b652a9f2-3e77-471e-8eae-8d4b06e37e2b",
   "metadata": {},
   "source": [
    "---\n",
    "title : \"01. 신경망 표현\"\n",
    "author : \"GC\"\n",
    "date : \"05/21/24\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6973a0-fa31-4439-9738-bb63a6754cf3",
   "metadata": {},
   "source": [
    "# 1. 층과 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661a283-a788-4e02-ba8f-bf31c31e7812",
   "metadata": {},
   "source": [
    "`1` 입력층을 제외한 층의 수가 총 층의 수이며 $L$로 표기한다.\n",
    "\n",
    "`2` 뉴런의 출력을 나타내는 법\n",
    "\n",
    "* $a^{[i]}$ : activation의 앞글자를 땀, $i$번째 층의 출력\n",
    "\n",
    "* $a^{[i]}_{j}$ : $i$번째 층의 $j$번째 출력\n",
    "\n",
    "* $n^{[i]}$ : $i$번째 층의 뉴런 수\n",
    "\n",
    "* 종합 1 : 2번째 층의 마지막($n$) 번째 뉴런 출력은? $\\to a^{[2]}_{n^{[2]}}$\n",
    "\n",
    "* 첫 번째 층의 모든 뉴런의 출력은?\n",
    "\n",
    "$$a^{[1]} = \\begin{bmatrix} a_{1}^{[1]} \\\\  \n",
    "                            a_{2}^{[1]} \\\\ \n",
    "                            \\dots \\\\ \n",
    "                            a_{n^{[1]}}^{[1]}\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53c54-90be-4a44-86a8-358ffec5754b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b5ca7c-3d2f-46fc-a879-83627ebc4122",
   "metadata": {},
   "source": [
    "# 2. 가중치와 편향"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1e697-90bf-4b0c-a620-3f2ee6e18a10",
   "metadata": {},
   "source": [
    "`1` 가중치는 `0.4, 0.6, 1` 처럼 전 층 뉴런의 곱해지는 숫자들이며 알파벳 $W$를 사용해 표기한다.\n",
    "\n",
    "`2` 가중치를 나타내는 법\n",
    "\n",
    "* $W^{[i]}$ : $i-1$과 $i$번째 층 사이에 있는 가중치들\n",
    "\n",
    "* $w^{[i]}_{j,k}$ : $i-1$층의 $j$번째 뉴런, $i$번째 층의 $k$번째 뉴런 사이의 가중치\n",
    "\n",
    "* 가중치를 행렬로 나타내는 법(ex : 2번째 층의 가중치들)\n",
    "\n",
    "$$W^{[2]} = \\begin{bmatrix} w_{1,1}^{[2]} & w_{2,1}^{[2]} \\cdots & w_{n^{[1]},1}^{[2]} \\\\\n",
    "                            w_{1,2}^{[2]} & w_{2,2}^{[2]} \\cdots & w_{n^{[1]},2}^{[2]} \\\\ \n",
    "                            \\cdots & \\cdots & \\cdots \\\\\n",
    "                            w_{1,n^{[2]}}^{[2]} & w_{2,n^{[2]}}^{[2]} \\cdots & w_{n^{[1]},n^{[2]}}^{[2]} \\\\ \n",
    "                            \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "\n",
    "`3` 편향을 나타내는 법($b$)\n",
    "\n",
    "* $b^{[i]}$ : $i$번째 층의 편향\n",
    "\n",
    "* $b^{[i]}_{j}$ : $i$번째 층의 $j$번째 뉴런의 편향\n",
    "\n",
    "* 첫 번째 층 뉴런들의 편향 벡터 표현\n",
    "\n",
    "$$b^{[i]} = \\begin{bmatrix} b_{1}^{[1]} \\\\  \n",
    "                            b_{2}^{[1]} \\\\ \n",
    "                            \\dots \\\\ \n",
    "                            b_{n^{[1]}}^{[1]}\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5cd862-5355-4bd6-a5bb-7e0266d9c6cd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a7467-c610-4cba-ad73-68645e0fafc5",
   "metadata": {},
   "source": [
    "# 3. 가중치와 편향 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e050e2-b7b6-4a5a-b3c5-4b4e04adf819",
   "metadata": {},
   "source": [
    "`1` 리스트안에 들어 있는 내용이 `[10,5,5,3]`이라면, 입력층에는 뉴런이 10개, 1번째 층에는 5개, 2번째 층에는 5개, 3번째 층에는 3개가 있다.\n",
    "\n",
    "`2` 첫 번째 층의 가중치 행렬은 `5 x 10` 차원의 행렬로 나타낼 수 있다.\n",
    "\n",
    "`3` 즉, $i$번째 층의 가중치 행렬의 차원은 $n^{[i]} \\times n^{[i-1]}$만큼의 차원을 가진다.\n",
    "\n",
    "`4` $i$번째 층의 편향은 $i$번째 층의 뉴런 숫자만큼의 차원을 가진다. $n^{[i]} \\times 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6d4063-296a-4973-997a-66eb5e09ee94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.22213732, -0.06183368,  0.28965512,  0.68111966, -0.10471657,\n",
       "         -0.10470923,  0.70624544,  0.34320724, -0.20995533,  0.24264023],\n",
       "        [-0.20724669, -0.20828068,  0.10820882, -0.85564494, -0.77140671,\n",
       "         -0.25146263, -0.45295185,  0.14053568, -0.40608071, -0.63160142],\n",
       "        [ 0.65545806, -0.10097023,  0.03019953, -0.63716676, -0.24345536,\n",
       "          0.04960609, -0.51473998,  0.16801726, -0.26861379, -0.13044941],\n",
       "        [-0.26909138,  0.82836399, -0.00603614, -0.47302271,  0.36785327,\n",
       "         -0.54597788,  0.09340664, -0.87639112, -0.59398286,  0.08803902],\n",
       "        [ 0.33025229,  0.07663823, -0.05171948, -0.13465767, -0.66121514,\n",
       "         -0.32192412, -0.20600392,  0.47275943,  0.15367077, -0.78845553]]),\n",
       " 'b1': array([ 0.14493476, -0.17221403, -0.30272872,  0.27354995,  0.461077  ]),\n",
       " 'W2': array([[ 0.41648113, -0.37530949, -0.13828398,  0.14814551,  0.43627704],\n",
       "        [-0.21429323, -0.08302922, -0.49476804, -0.53495987,  0.36337259],\n",
       "        [ 0.60652898, -0.03220391,  0.44879356,  0.16172855, -0.28850632],\n",
       "        [ 0.16162103,  0.68783086, -0.01602189,  0.69972991, -1.17158563],\n",
       "        [ 0.36756597,  0.03892863, -0.13372015,  0.04103667, -0.88886784]]),\n",
       " 'b2': array([-0.09824025,  0.1597056 ,  0.66093431, -0.23177749, -0.36156933]),\n",
       " 'W3': array([[-0.28968956,  0.52850766,  0.18980454, -0.3058572 ,  0.29633509],\n",
       "        [ 0.05604775,  0.55924745, -0.40533054, -0.18917583, -0.22638375],\n",
       "        [-0.84496075,  0.17096512,  0.15072033,  0.00295226, -0.13543894]]),\n",
       " 'b3': array([-0.81716468, -0.24285969, -0.19786632])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | code-fold : true\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def initialize_parameters(neurons_per_layer):\n",
    "    \"\"\"신경망의 가중치와 편향을 초기화해주는 함수\"\"\"\n",
    "    L = len(neurons_per_layer)- 1 \n",
    "    parameters = {}\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        parameters['W' + str(l)] = np.random.randn(neurons_per_layer[l],neurons_per_layer[l-1]) * np.sqrt(1/neurons_per_layer[l])\n",
    "        parameters['b' + str(l)] = np.random.randn(neurons_per_layer[l])*np.sqrt(1/neurons_per_layer[l])\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "neurons_per_layer = [10, 5, 5, 3]\n",
    "initialize_parameters(neurons_per_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88805c68-d0f0-4fe5-895a-2a7975d69904",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e3621-c407-4324-849f-85fa830cd8b7",
   "metadata": {},
   "source": [
    "# 4. 입력 변수와 목표변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51033b60-3a35-4845-987f-e0d978ad89c2",
   "metadata": {},
   "source": [
    "`1`  MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6792745-e3bc-4906-91a4-2723bad1d4bf",
   "metadata": {},
   "source": [
    "<center><img src = \"3.png\" width = 500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca0139-9171-4dbc-9c00-6bb45ed676ec",
   "metadata": {},
   "source": [
    "* $x^{(i)}$ : $i$번째 데이터의 입력 변수(벡터 값임)\n",
    "\n",
    "* $x^{(i)}_{j}$ : $i$번째 데이터의 $j$번째 픽셀 값\n",
    "\n",
    "* $y^{(i)}$ : $i$번째 데이터의 목표 변수 (lable 값) $\\to$ 모델링 시에는 `one-hot encoding`을 통해 범주형 변수로 바꿔준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a408080-23c6-4057-9a66-6833ccc9dd53",
   "metadata": {},
   "source": [
    "$$y^{(1)}  = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25a726-ce62-4c03-be45-afd1d5b88bd7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252123e-5fd7-4b0e-bb43-47757144f6d3",
   "metadata": {},
   "source": [
    "# 5. 순전파"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3e4f7-4ede-4a7c-97a0-75893ac0582b",
   "metadata": {},
   "source": [
    "인풋 데이터가 들어가서 마지막 층까지 처리돼서 출력되는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61935a-df35-4248-8368-a8c4d7c28b9e",
   "metadata": {},
   "source": [
    "`1` 수학적 표현\n",
    "\n",
    "* 입력층과 첫 번째 층 사이 순전파에서 첫 번째 뉴런의 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a77e7-5429-43e4-8b9a-e96e88364605",
   "metadata": {},
   "source": [
    "$$z_{1}^{[1]} = w_{1,1}^{[1]}a_{1}^{[0]} + w_{2,1}^{[1]}a_{2}^{[0]} + \\cdots +  w_{n^{[0]},1}^{[1]}a_{n^{[0]}}^{[0]} + b^{[1]}_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78fc8d5-5ece-4a53-bf8f-4529835c2745",
   "metadata": {},
   "source": [
    "* 첫 번째 뉴런의 활성화 함수(`여기선 시그모이드`)를 거친 최종 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299c5e1-b133-45a8-98a9-95731387c8e3",
   "metadata": {},
   "source": [
    "$$a_1^{[1]} = \\sigma(z_1^{[1]})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f30aa0-4135-471d-a92c-60738d8d8192",
   "metadata": {},
   "source": [
    "`2` 일반화된 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe112b-8d6c-4f13-816d-d307d17b45d1",
   "metadata": {},
   "source": [
    "$$z^{[l]} = W^{(l)}a^{[l-1]} + b^{[l]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547f3eb-677e-4b67-b0db-716f4353645b",
   "metadata": {},
   "source": [
    "$$a^{[l]} = \\sigma(z^{[l]})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e798a51-bc79-4d93-a171-3badea04d044",
   "metadata": {},
   "source": [
    "`3` 코드구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac423463-122c-422c-a737-40ed3cf11765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39847399, 0.63077823, 0.79833093, 0.9305652 , 0.67941177,\n",
       "       0.67579947, 0.05318345, 0.37468731, 0.12677545, 0.64191774])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | code-fold : true\n",
    "# 인공 신경망 구현에 사용할 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# numpy 임의성 조절\n",
    "np.random.seed(42)\n",
    "\n",
    "# 데이터 셋 가지고 오기\n",
    "dataset = pd.read_csv('./data/MNIST_preprocessed.csv', sep=',', header=None).values\n",
    "\n",
    "# 입력, 목표 변수 데이터 셋 나누기\n",
    "X = dataset[:, 0:784]\n",
    "Y = dataset[:, 784:]\n",
    "\n",
    "# training, testing 데이터 셋 나누기\n",
    "X_train, X_test = X[0:250,], X[250:,]\n",
    "Y_train, Y_test = Y[0:250,], Y[250:,]\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"시그모이드 함수\"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def initialize_parameters(nodes_per_layer):\n",
    "    \"\"\"신경망의 가중치와 편향을 초기화해주는 함수\"\"\"\n",
    "    L = len(nodes_per_layer) - 1  # 층 개수 저장\n",
    "    parameters = {}\n",
    "    \n",
    "    # 1층 부터 L 층까지 돌면서 가중치와 편향 초기화\n",
    "    for l in range(1, L+1):\n",
    "        parameters['W' + str(l)] = np.random.randn(nodes_per_layer[l], nodes_per_layer[l-1]) * np.sqrt(1. / nodes_per_layer[l])\n",
    "        parameters['b' + str(l)] = np.random.randn(nodes_per_layer[l]) * np.sqrt(1. / nodes_per_layer[l])\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "def feed_forward(x, parameters):\n",
    "    \"\"\"순전파 함수\"\"\"\n",
    "    cache = {'a0': x}\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        # 전 층 뉴런의 출력, 현재 층 뉴런들의 가중치, 편향 데이터를 가지고 온다.\n",
    "        a_prev = cache['a' + str(l-1)]\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        \n",
    "        # 데이터로 z와 a를 계산한다.\n",
    "        z = W @ a_prev + b\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        # 결과 값을 캐쉬에 저장한다.\n",
    "        cache['z' + str(l)] = z\n",
    "        cache['a' + str(l)] = a\n",
    "                \n",
    "    return a, cache\n",
    "\n",
    "\n",
    "# 테스트 코드\n",
    "neurons_per_layer = [784, 128, 64, 10]\n",
    "parameters = initialize_parameters(neurons_per_layer)\n",
    "feed_forward(X_train[0], parameters)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabd016-eef1-46be-a760-3c322d51072d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac856fc-417b-4c86-a3c5-9098aafd0b6a",
   "metadata": {},
   "source": [
    "# 6. 가설 함수와 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d09ac-e631-4fd4-bf91-ee174b4232a1",
   "metadata": {},
   "source": [
    "`1` 신경망 학습 : 입력 변수에 대한 목표 변수를 잘 예측하는 가중치와 편향을 찾는 것\n",
    "\n",
    "`2` 가설 함수 : 주어진 입력 변수를 통해 예측값을 계산하는 함수 \n",
    "\n",
    "* 예측값은 순전파를 통해 계산되며 신경망의 가중치와 편향에 따라 달라진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f6595-a8dd-4536-b079-178d4d651c3d",
   "metadata": {},
   "source": [
    "$$h_{w}(x) = a^{[L]} = \\sigma(W^{[L]}a^{[L-1]} + b^{[L]})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f3f44-48ac-49fe-9fcc-283aab0df83b",
   "metadata": {},
   "source": [
    "`3` 손실 함수 $J(W)$\n",
    "\n",
    "* 학습을 통해 가중치와 편향을 변경하는 기준\n",
    "\n",
    "* 종류가 매우 다양, 대표적인 예 : 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2d95e-c0c8-41d9-bb71-1b43dae0c8c9",
   "metadata": {},
   "source": [
    "$$J(W) = \\frac {1}{2mn^{[L]}}\\sum_{i=1}^{m}\\sum_{k=1}^{n^{[L]}} (h_w(x^{(i)})_k - y_k^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d1dab-6d66-45c7-94fe-2c2f83169850",
   "metadata": {},
   "source": [
    "* 식이 좀 어렵게 보이지만, 그냥 모든 데이터에 대해서 모든 뉴런의 예측 제곱 오차 평균을 구하겠다는 내용임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c88d6-021b-4ad5-89ec-1913c366eb58",
   "metadata": {},
   "source": [
    "* 예제 : 하나의 데이터에 대해서 신경망의 가설함수 아웃풋과 실제 목표 변수가 다음과 같이 있다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258efa6d-2ffd-4e31-81f4-8f173c338107",
   "metadata": {},
   "source": [
    "$$h_{W}(x^{(i)}) = \\begin{bmatrix} 0.1 \\\\ 0.4 \\\\ 0.95 \\\\ 0.5 \\\\ 0.2 \\\\ 0.4 \\\\ 0.2 \\\\ 0.2 \\\\ 0.1 \\\\ 0.0 \\end{bmatrix}, \\quad y^{(i)} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\0 \\\\0 \\\\ 0\\\\ 0  \\\\0 \\\\ 0\\\\ 0\\end{bmatrix}, \\quad (h_w(x^{(i)})_k - y_k^{(i)})^2 = \\begin{bmatrix} 0.01 \\\\ 0.16 \\\\ 0.0025 \\\\ 0.25 \\\\ 0.04 \\\\ 0.16 \\\\ 0.04 \\\\ 0.04 \\\\ 0.01 \\\\ 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e617e-596b-4497-970c-7117e9383e22",
   "metadata": {},
   "source": [
    "* 이렇게 하면 하나의 데이터데 대한 평균 제곱 오차를 구한 것이며, 이를 모든 학습 데이터에 대해서 반복하여 합하면 된다. 그리고 이를 총 데이터 개수와 출력층 뉴런의 개수로 나누어 주는 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
