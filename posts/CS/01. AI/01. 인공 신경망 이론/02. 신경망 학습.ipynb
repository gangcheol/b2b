{
 "cells": [
  {
   "cell_type": "raw",
   "id": "319ae2c2-9a7d-4224-a15e-ea945c82f988",
   "metadata": {},
   "source": [
    "---\n",
    "title : \"02. 신경망 학습\"\n",
    "author : \"GC\"\n",
    "date : \"05/27/24\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefdd1eb-6f3e-4ef7-be8c-9fdb0c919c73",
   "metadata": {},
   "source": [
    "# 1. 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085ab52-607b-4e9c-8a5d-1914d12f60bf",
   "metadata": {},
   "source": [
    "## 변수가 하나일 떄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194ea4d-444f-43e4-88dc-9be2482884a2",
   "metadata": {},
   "source": [
    "`-` 손실함수 $J$에 하나의 변수 $w$가 있다고 가정하자. 정된 손실함수는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4080209-319c-4224-8e29-75b1d6469348",
   "metadata": {},
   "source": [
    "$$J(w) = (w-1)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18de663f-cc63-4791-89e1-0474996e34e2",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial}{\\partial w} J(w) = 2w-2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e231001-343c-4687-93c0-f806cb31687b",
   "metadata": {},
   "source": [
    "`-` 경사하강법은 특정 $w$값에서 시작해서 함수의 경사 또는 기울기를 사용해 함수(`손실함수`)의 출력을 더 낮게 하는 $w$값을 찾는 알고리즘이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6731fc-574b-4d66-8d00-caf212a131e3",
   "metadata": {},
   "source": [
    "> ex1. $w = 2 \\to \\frac{\\partial}{\\partial w} J(w) = 2$\n",
    ">\n",
    "> ex2. $w = -1 \\to \\frac{\\partial}{\\partial w} J(w) = -4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b3a6a-ae25-4723-8a76-5bbcd5e9538c",
   "metadata": {},
   "source": [
    "`-` 경사 하강법은 이렇게 함수의 경사를 사용해서 손실 함수의 출력을 줄여나가는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a90b1-3096-40d5-a9b3-23e07d962e05",
   "metadata": {},
   "source": [
    "## 변수가 두 개 이상일 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d602a-1b1f-4a54-9abb-9345f4bbd036",
   "metadata": {},
   "source": [
    "`1` 변수가 두 개 이상일 경우 손실 함수 $J$를 각각의 변수 하나씩으로 편미분 한다.\n",
    "\n",
    "* 편미분 : 두 개 이상의 변수로 이뤄진 함수를 하나의 변수로 미분 하는 것\n",
    "\n",
    "`2` 편미분 한 값들을 벡터로 묶으면 이 벡터가 함수의 경사가 된다.\n",
    "\n",
    "`3` 이 벡터는 $J$가 가장 빨리 늘어나는 방향을 가리킨다.\n",
    "\n",
    "`4` $J$의 출력을 줄이는 것이 목적이므로 원래 변수 텍터에서 경사를 빼줘야 한다.\n",
    "\n",
    "`5` 즉, 학습을 하며 초기 가중치와 편향들에서, 해당 변수들에 대해서 $J$를 편미분한 값들을 때주면 되는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e64aa2-e8a2-4cfd-9d75-4aff66036f67",
   "metadata": {},
   "source": [
    "* 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe89846-3891-4c93-827d-49b711ecc851",
   "metadata": {},
   "source": [
    "$$w_{i,j}^{(l)} \\leftarrow w_{i,j}^{(l)} - \\alpha \\frac{\\partial}{\\partial w_{i,j}^{(l)}}J(W) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c411f-df6b-4273-8a2b-f53c2a06afd7",
   "metadata": {},
   "source": [
    "$$b_{i,j}^{(l)} \\leftarrow b_{i,j}^{(l)} - \\alpha \\frac{\\partial}{\\partial b_{i,j}^{(l)}}J(W) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd19717-3031-4f67-89f9-fc1a5786794e",
   "metadata": {},
   "source": [
    "$$\\divideontimes \\,\\,\\alpha : \\text{learning rate}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588960b7-03c8-411a-8b9f-c57fcdc1aaa5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99d3e0-1455-4fb9-9780-5dfb04c071ef",
   "metadata": {},
   "source": [
    "# 2. 신경망 손실 함수 경사 계산이 복잡한 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306efa15-c042-4ee4-a0da-c87208751203",
   "metadata": {},
   "source": [
    "`-` 가중치에 대한 미분 : 가중치를 바꿨을 때 손실 함수가 어떻게 변하는지 확인하는 것\n",
    "\n",
    "`-` 신경망에서는 여러 개의 층과 뉴런으로 구성되어 있기 때문에 학습을 위한 가중치 연산이 급증하기 때문에 계산이 복잡하다.\n",
    "\n",
    "* 첫 번째 층의 출력이 바뀌면 이어지는 층에서 뉴런들이 복합적으로 출력이 바뀌기 때문에 손실함수 계산이 복잡해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880207fc-317c-4ac7-be66-4ed6f133d8d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcaeacc-4e51-4e5c-b1dc-3e98eb3dceec",
   "metadata": {},
   "source": [
    "# 3. 신경망 손실 함수의 볼록도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe5157-a34f-49b2-93d1-53985f9d6f4f",
   "metadata": {},
   "source": [
    "`-` 기본 지도학습 알고리즘들은 손실함수가 아래로 볼록한(convex)함수라고 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4c124-1222-4842-bf86-bb7310d98dd1",
   "metadata": {},
   "source": [
    "<center><img src = \"4.png\" width = 500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b5a174-2c05-428b-ae77-d0f7ddda498c",
   "metadata": {},
   "source": [
    "`-` 해당 함수는 극소점이 하나밖에 없으며, 최소점을 가진다.\n",
    "\n",
    "* 그렇기 때문에, 함수의 어느 지점에서 경사 하강법을 시작해도, 충분히 많은 반복을 하면?\n",
    "\n",
    "* 결국 $J$의 최소점에 해당하는 $\\theta$값을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f47db-a7f1-4644-b277-1af4f7e90a61",
   "metadata": {},
   "source": [
    "`-` 그러나 신경망 손실 함수 볼록도는 다음과 같이 볼록하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677aec1-cde5-47be-b413-44244fb236f7",
   "metadata": {},
   "source": [
    "<center><img src = \"5.png\" width = 500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa75b19-7950-402a-a3fc-438a6941a33b",
   "metadata": {},
   "source": [
    "`-` 선형 회귀와 같이 평균 제곱 오차를 사용하고 있긴 해도, 너무 복잡한 합성 함수 이기 때문이다.\n",
    "\n",
    "* 이는 로그 손실 함수, 다른 함수를 사용해도 마찬가지임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0084-01ba-43d3-92a3-61f233a8bd78",
   "metadata": {},
   "source": [
    "`-` 위 그림과 같이 여러 개의 극소점들이 있고 이 중에서 가장 손실이 작은 점만이 최소점이다.\n",
    "\n",
    "* 그렇기 때문에 $W,b$를 임의의 값들로 초기화하고 경사 하강법을 적용해도 손실이 가장 작게 만드는 $w,b$를 찾을 수 있다고 단언 할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b7a52-05b5-44dc-bd68-009b889c082f",
   "metadata": {},
   "source": [
    "`-` 그러나 찾은 지점이 최소점이라는 보장이 없어도 신경망에서는 최적화를 위해 경사 하강법을 적용한다.\n",
    "\n",
    "* 이유 1 : $w,b$에 어떤 값들이 들어가야 할 지 전혀 모르는 상황에서, 어떤 임의 값에서 시작해도 그 값들 보다는 손실을 줄일 수 있기 때문!\n",
    "\n",
    "* 이유 2 : 이렇게 해서 찾은 극소점들에서 얻는 성능이 많은 경우 충분히 좋게 나오기 때문이다.\n",
    "\n",
    "`-`  손실 함수가 볼록하지 않다는 문제점을 극복하기 위한 한 가지 방법은 무게와 편향 값들을 임의로 초기화를 여러 번해서 경사 하강법을 많이 해본 이후, 가장 성능이 좋게 나온 모델을 사용하는 것!($\\star\\star\\star$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
